{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM1YJeDv1Z7ONJD6kOQD5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2023ad05120-lab/AI_VolumeNet_Capstone_Project/blob/main/generate_synthetic_dataset.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jARgMiJUMKZ0",
        "outputId": "caa4352f-7da1-4c77-940c-35233e4725d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading background 1...\n",
            "⚠️ Warning: Background 1 not readable, removing.\n",
            "⬇️ Downloading background 2...\n",
            "⚠️ Warning: Background 2 not readable, removing.\n",
            "⬇️ Downloading background 3...\n",
            "⚠️ Warning: Background 3 not readable, removing.\n",
            "\n",
            "Summary Report:\n",
            "Train images: 80\n",
            "Val images: 20\n",
            "YOLO label files: 100\n",
            "Annotations.json exists: True\n",
            "Metadata.csv exists: True\n",
            "data.yaml exists: True\n",
            "Dataset saved to: /content/synthetic_dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import shutil\n",
        "\n",
        "# Household object classes\n",
        "CLASSES = [\"mug\", \"plate\", \"bowl\", \"bottle\", \"spoon\", \"fork\", \"knife\", \"pan\", \"glass\", \"reference_card\"]\n",
        "\n",
        "BACKGROUND_DIR = \"backgrounds/\"\n",
        "OUTPUT_DIR = \"synthetic_dataset/\"\n",
        "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(OUTPUT_DIR, \"val\")\n",
        "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_DIR, exist_ok=True)\n",
        "os.makedirs(BACKGROUND_DIR, exist_ok=True)\n",
        "\n",
        "# ✅ Direct Unsplash image links\n",
        "BACKGROUND_URLS = [\n",
        "    \"https://images.unsplash.com/photo-1600891964599-f61ba0e24092?auto=format&fit=crop&w=640&q=80\",\n",
        "    \"https://images.unsplash.com/photo-1590080875831-7c1d6f5d8e3d?auto=format&fit=crop&w=640&q=80\",\n",
        "    \"https://images.unsplash.com/photo-1617196039897-2c5a1f8a1c2a?auto=format&fit=crop&w=640&q=80\",\n",
        "    \"https://images.unsplash.com/photo-1589308078053-1c1d6f5d8e3d?auto=format&fit=crop&w=640&q=80\",\n",
        "]\n",
        "\n",
        "def download_backgrounds():\n",
        "    for i, url in enumerate(BACKGROUND_URLS):\n",
        "        out_path = os.path.join(BACKGROUND_DIR, f\"bg_{i}.jpg\")\n",
        "        if not os.path.exists(out_path):\n",
        "            print(f\"⬇️ Downloading background {i}...\")\n",
        "            img_data = requests.get(url).content\n",
        "            with open(out_path, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "        test_img = cv2.imread(out_path)\n",
        "        if test_img is None:\n",
        "            print(f\"⚠️ Warning: Background {i} not readable, removing.\")\n",
        "            os.remove(out_path)\n",
        "\n",
        "def generate_random_object(class_name, img_size=(480,640)):\n",
        "    h, w = img_size\n",
        "    x1, y1 = random.randint(50, w//2), random.randint(50, h//2)\n",
        "    x2, y2 = x1 + random.randint(40,120), y1 + random.randint(40,120)\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "def generate_depth_map(objects, img_size=(480,640)):\n",
        "    h, w = img_size\n",
        "    depth = np.zeros((h,w), dtype=np.uint8)\n",
        "    for i, obj in enumerate(objects):\n",
        "        x1,y1,x2,y2 = obj[\"bbox\"]\n",
        "        depth_value = 255 - i*30\n",
        "        cv2.rectangle(depth, (x1,y1), (x2,y2), depth_value, -1)\n",
        "    return depth\n",
        "\n",
        "def save_yolo_labels(image_id, annotations, save_dir, img_size=(480,640)):\n",
        "    h, w = img_size\n",
        "    label_path = os.path.join(save_dir, f\"{image_id.replace('.jpg','.txt')}\")\n",
        "    with open(label_path, \"w\") as f:\n",
        "        for ann in annotations:\n",
        "            cls_id = CLASSES.index(ann[\"class\"])\n",
        "            x1,y1,x2,y2 = ann[\"bbox\"]\n",
        "            x_center = ((x1 + x2) / 2) / w\n",
        "            y_center = ((y1 + y2) / 2) / h\n",
        "            width = (x2 - x1) / w\n",
        "            height = (y2 - y1) / h\n",
        "            f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "def generate_scene(scene_id, save_dir, num_objects=3):\n",
        "    bg_files = os.listdir(BACKGROUND_DIR)\n",
        "    if not bg_files:\n",
        "        bg = np.ones((480,640,3), dtype=np.uint8) * 255\n",
        "    else:\n",
        "        bg_path = os.path.join(BACKGROUND_DIR, random.choice(bg_files))\n",
        "        bg = cv2.imread(bg_path)\n",
        "        if bg is None:\n",
        "            bg = np.ones((480,640,3), dtype=np.uint8) * 255\n",
        "        else:\n",
        "            bg = cv2.resize(bg, (640,480))\n",
        "\n",
        "    annotations, metadata = [], []\n",
        "    for i in range(num_objects):\n",
        "        cls = random.choice(CLASSES[:-1])\n",
        "        box = generate_random_object(cls)\n",
        "        annotations.append({\"class\": cls, \"bbox\": box})\n",
        "        width_cm = random.uniform(5,15)\n",
        "        height_cm = random.uniform(5,20)\n",
        "        volume_cm3 = width_cm * height_cm * random.uniform(2,5)\n",
        "        metadata.append({\n",
        "            \"image_id\": f\"scene_{scene_id}.jpg\",\n",
        "            \"class\": cls,\n",
        "            \"width\": width_cm,\n",
        "            \"height\": height_cm,\n",
        "            \"volume\": volume_cm3,\n",
        "            \"bbox\": box\n",
        "        })\n",
        "        cv2.rectangle(bg, (box[0], box[1]), (box[2], box[3]), (0,255,0), 2)\n",
        "        cv2.putText(bg, cls, (box[0], box[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
        "\n",
        "    # Reference card\n",
        "    ref_box = [20, 400, 100, 460]\n",
        "    cv2.rectangle(bg, (ref_box[0], ref_box[1]), (ref_box[2], ref_box[3]), (255,0,0), 2)\n",
        "    annotations.append({\"class\": \"reference_card\", \"bbox\": ref_box})\n",
        "\n",
        "    # Save RGB image\n",
        "    img_path = os.path.join(save_dir, f\"scene_{scene_id}.jpg\")\n",
        "    cv2.imwrite(img_path, bg)\n",
        "\n",
        "    # Save depth map\n",
        "    depth_map = generate_depth_map(annotations)\n",
        "    depth_path = os.path.join(save_dir, f\"scene_{scene_id}_depth.png\")\n",
        "    cv2.imwrite(depth_path, depth_map)\n",
        "\n",
        "    # Save YOLO labels\n",
        "    save_yolo_labels(f\"scene_{scene_id}.jpg\", annotations, save_dir)\n",
        "\n",
        "    return annotations, metadata\n",
        "\n",
        "def main(num_scenes=100, split_ratio=0.8):\n",
        "    download_backgrounds()\n",
        "    all_annotations, all_metadata = [], []\n",
        "    train_count = int(num_scenes * split_ratio)\n",
        "\n",
        "    for i in range(num_scenes):\n",
        "        save_dir = TRAIN_DIR if i < train_count else VAL_DIR\n",
        "        ann, meta = generate_scene(i, save_dir, num_objects=random.randint(2,5))\n",
        "        all_annotations.extend(ann)\n",
        "        all_metadata.extend(meta)\n",
        "\n",
        "    # Save COCO-style annotations\n",
        "    with open(os.path.join(OUTPUT_DIR, \"annotations.json\"), \"w\") as f:\n",
        "        json.dump(all_annotations, f, indent=4)\n",
        "\n",
        "    # Save metadata.csv\n",
        "    pd.DataFrame(all_metadata).to_csv(os.path.join(OUTPUT_DIR, \"metadata.csv\"), index=False)\n",
        "\n",
        "    # Write YOLO data.yaml\n",
        "    yaml_path = os.path.join(OUTPUT_DIR, \"data.yaml\")\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        f.write(f\"train: {os.path.abspath(TRAIN_DIR)}\\n\")\n",
        "        f.write(f\"val: {os.path.abspath(VAL_DIR)}\\n\")\n",
        "        f.write(f\"nc: {len(CLASSES)}\\n\")\n",
        "        f.write(f\"names: {CLASSES}\\n\")\n",
        "\n",
        "    # ✅ Summary report\n",
        "    print(\"\\nSummary Report:\")\n",
        "    print(f\"Train images: {len([f for f in os.listdir(TRAIN_DIR) if f.endswith('.jpg')])}\")\n",
        "    print(f\"Val images: {len([f for f in os.listdir(VAL_DIR) if f.endswith('.jpg')])}\")\n",
        "    print(f\"YOLO label files: {len([f for f in os.listdir(TRAIN_DIR) if f.endswith('.txt')]) + len([f for f in os.listdir(VAL_DIR) if f.endswith('.txt')])}\")\n",
        "    print(f\"Annotations.json exists: {os.path.exists(os.path.join(OUTPUT_DIR,'annotations.json'))}\")\n",
        "    print(f\"Metadata.csv exists: {os.path.exists(os.path.join(OUTPUT_DIR,'metadata.csv'))}\")\n",
        "    print(f\"data.yaml exists: {os.path.exists(yaml_path)}\")\n",
        "    print(f\"Dataset saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(num_scenes=100, split_ratio=0.8)\n"
      ]
    }
  ]
}